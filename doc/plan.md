# RakugakiBattle 仕様
2019/06/06 新規作成

2019/07/06 追記/変更

## シーケンス図
![シーケンス図](sequence.png)

### フロントサイド
android にて実装  
そのためJava を使う

### サーバーサイド
機械学習が使いやすいPython3 を使う

### 機械学習
CNNを用いてクラススコアを算出  
実行にはPython3 を使う


## フロントサイド

### ゲーム開始
ニックネームを取得しサーバーに投げる  
ニックネームは半角英数のみとする  
ここでサーバーに接続する

### 落書き開始
サーバーからお題と, ユーサーIDを受け取る  
サーバーからゲーム開始合図を受け取ったら以下を開始  
サーバから受け取ったお題を表示し, 落書きを開始する  
できればタイマーを表示する

### 落書き終了
制限時間になったら音がなるといいかも  
制限時間になったら落書きを .jpg 形式で保存する  
ファイル名は[{ユーサーID}-{ニックネーム}.jpg]  
保存した落書きをサーバーに投げる

### 結果を返すまでの待ち時間
(もしCPUでYOLOv3を動かす場合)  
説明動画でも流す?  
いらない気がするけど...

### 結果の表示
結果を表示する  
音があるとインパクトあるかも  
その後サーバとの接続を切断し, ゲーム開始街状態に入る  


## サーバーサイド

### オブジェクト
#### class User
self.IPAddress (String) # IPアドレス  
self.PortNumber (int) # ポート番号  
self.ID (int) # ユーザーID インスタンス作成時に生成  
self.name (String) # ユーザー名  
self.img-path (String) # 落書きのファイルパスを格納  
self.result (dict) # 機械学習にて検出したものとその類似度のペアを格納  
self.score (int) # 算出したスコアを表示する  
ランダムでユーザーIDを振る  

#### class Room
self.roomID (int) # 部屋ID インスタンス作成時に生成  
self.user (list) # 部屋に入っているユーザーを格納する配列  
	         # User インスタンスを格納する  
self.theme (String) # お題 部屋を締め切り, ゲームを開始する前に決める  
外部ファイル(多分 class.txt) からお題を取得  
その中からランダムで選定する  

### お題決定
クライアントから接続要求を受けたあと  
1. Userオブジェクトを生成  
2. User を部屋に入れる  
3. クライアントに対し, [ユーザーID,お題]を返す  

[部屋の入り方]  
待ち状態の部屋がない -> 部屋を作成  
待ち状態の部屋がある -> その部屋に入る  

### 画像取得
画像をフォルダに保存し, そのパスを User インスタンスに格納する  

### 後処理
機械学習側から返された {"label":socre} を受け取り User インスタンスに格納  
受け取ったリストの中からお題と一致する項目を探す  
お題と一致する項目がある -> その類似度がスコア  
お題と一致する項目がない -> 0点?  
算出したスコアを User インスタンスに格納する  

### 結果の生成
部屋に属するユーザーが全員スコアの算出が終わったらクライアントに結果を返す  

## 機械学習

### 前処理
1. ノイズの除去 (黒点などがある場合取り除く)
2. 余白の切り取り --(クライアントサイド)--
3. グレースケールに変換
4. 輝度値を反転
5. 画像の正規化 0-256 -> 0-1
6. 画像のリサイズ (縦横比を保ったまま)

### 推論

あらかじめmodel.h5 を作成しておく  

推論の際にはmodel.h5 ファイルを読み込み, それをもとに推論する

### 検出結果を返す
検出結果を Python3 の dict(辞書) 形式で返す  
{"label":score}

### 参考文献
[Quiita](https://qiita.com/massie_g/items/a2bcfac4fed66b1b0717)

### memo
検出開始も検出結果を返すも一つの関数で行う  
引数:画像のパス
戻り値:{"label":score}
/python/darknet.py を参考に作る 

# 追加機能1

## 結果表示機能について

表示するものは以下の通り

1. スコア (お題のもの)
   - 1人の場合, スコアとランキング順位
   - 2人対戦の場合, 勝利したかどうか
2. スコア (上位3クラス分)
   - 1人の場合, 全クラスのスコア
   - 2人対戦の場合, 相手のスコアも表示
   - どちらもスコアが高い順に保存
   - 表形式のほうが見やすい?
3. ランキング
   - 全体としてのランキング
   - ただしランキング用のページがある場合, そこだけでもいいかも

## 逐次推論について

以下のタイミングで, 推論の結果を得る + リアルタイムに表示

1. 一定時間経過したとき (例: 5s, 10s)
2. キーストロークごとに

処理の手順

1. 上記タイミング時にサーバーに画像を送る
2. サーバーは機械学習に投げ, 推論結果を受け取る
3. サーバーからクライアントに推論結果を投げる
   - 上位3クラス
   - お題のクラスのスコア
   - 対戦の場合: 相手のスコア
   - etc... (まだ決めてない)
4. 受け取った結果をお絵描きの邪魔にならないように表示 (ポップアップ等はしない)

## model ごとに結果を格納

実際にテストした際のスコアを (できる場合, その時受け付けた画像データも) 保存し検討会での材料にする

保存するデータ

1. model 情報 (どのモデルを使用したか)
2. お題
3. 全クラスのスコア (この時, モデルごとにクラス数が違う可能性があることに注意)
4. (できるなら) 画像データ

例 car, cat, dog の3クラスの場合
ディレクトリ構造

```
|-- model1 // 数が増えるごとに model2, model3 ... となる
 |- log // TensorBoard 用ログフォルダ もしTensorBoard を使用する場合, このディレクトリを指定
 |- Accurancy.png // epochsを変化させたときの分類精度の推移を示すグラフ
 |- info.txt // 学習時のパラメータ等の情報を記載したファイル
 |- label.csv // 使用したデータセットのクラスとそれに紐付けた値を格納したファイル
 |- log.csv // 各epochs ごとの acc, loss, val_acc, val_loss を格納したファイル
 |- Loss.png // epochsを変化させたときの損失関数の推移を示すグラフ
 |- model.h5 // 学習したモデルを格納したh5 ファイル
 |- result.csv // <- これを作成
 |- img // もし画像を保存する場合
  |- 1.png
  |- 2.png
```

result.csv

```
odai,car,cat,dog,img_path
car,0.925,0.005,0.070,/data/1.png
cat,0.30,0.65,0.05,/data/2.png
...
```

# 追加機能2

## モデルごとにモードを分ける

ゲームを行う際, ユーザーが(あるいはこちら側で事前に) 複数あるモデルを選択してゲームが行えるように拡張する.  

このとき, モデルが格納されているフォルダーの数は事前に分からない(動的に決定する) とする.  

モデルが格納されているディレクトリー構造は前述(model ごとに結果を格納 で記載したディレクトリ構造)と同じ.  

各ファイル名は固定である. また, 今後ファイルが増える可能性あり.  

### クライアントサイド

ゲーム画面に遷移する前に (名前等を入力する段階で) サーバーに対し, どのモデルでゲームを行うか, その情報を送信する.  

もしできる場合, サーバーから事前にモデルがいくつあるのか情報をもらい, それに応じてドロップボックスを動的に生成する.  

もしできない場合, サーバーにどのモデルでゲームを行うのかを入力するテキストボックスを作成し, そこに数字を入力してもらう. (1~)

### サーバーサイド

クライアントから受け取ったモデルの情報を元に, 推論させる際のモデルを指定するように変更する.  

(たぶんpredict.py を変更すればOK)